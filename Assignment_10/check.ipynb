{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd790c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "END_TAG = \"<END>\"\n",
    "\n",
    "\n",
    "def read_tagged_corpus(path):\n",
    "    sentences = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            words = []\n",
    "            tags = []\n",
    "            for token in line.split():\n",
    "                if \"/\" not in token:\n",
    "                    continue\n",
    "                word, tag = token.rsplit(\"/\", 1)\n",
    "                words.append(word)\n",
    "                tags.append(tag)\n",
    "            if words:\n",
    "                sentences.append((words, tags))\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def make_folds(data, k=5, seed=42):\n",
    "    shuffled = list(data)\n",
    "    random.Random(seed).shuffle(shuffled)\n",
    "    fold_size = max(1, len(shuffled) // k)\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < k - 1 else len(shuffled)\n",
    "        folds.append(shuffled[start:end])\n",
    "    return folds\n",
    "\n",
    "\n",
    "def train_hmm(train_data):\n",
    "    tag_counts = Counter()\n",
    "    emission_counts = defaultdict(Counter)\n",
    "    transition_counts = defaultdict(Counter)\n",
    "    vocabulary = set()\n",
    "\n",
    "    for words, tags in train_data:\n",
    "        prev_tag = START_TAG\n",
    "        transition_counts[prev_tag]  # ensure key exists\n",
    "        for word, tag in zip(words, tags):\n",
    "            vocabulary.add(word)\n",
    "            tag_counts[tag] += 1\n",
    "            emission_counts[tag][word] += 1\n",
    "            transition_counts[prev_tag][tag] += 1\n",
    "            prev_tag = tag\n",
    "        transition_counts[prev_tag][END_TAG] += 1\n",
    "\n",
    "    tags = list(tag_counts.keys())\n",
    "    vocab_size = len(vocabulary)\n",
    "    num_tags = len(tags)\n",
    "\n",
    "    log_transitions = defaultdict(dict)\n",
    "    for prev_tag, next_counter in transition_counts.items():\n",
    "        total = sum(next_counter.values())\n",
    "        for candidate in tags + [END_TAG]:\n",
    "            count = next_counter.get(candidate, 0)\n",
    "            log_transitions[prev_tag][candidate] = math.log(\n",
    "                (count + 1) / (total + num_tags + 1)\n",
    "            )\n",
    "\n",
    "    log_emissions = defaultdict(dict)\n",
    "    log_unknown = {}\n",
    "    for tag in tags:\n",
    "        total = sum(emission_counts[tag].values())\n",
    "        denom = total + vocab_size + 1\n",
    "        log_unknown[tag] = math.log(1 / denom)\n",
    "        for word, count in emission_counts[tag].items():\n",
    "            log_emissions[tag][word] = math.log((count + 1) / denom)\n",
    "\n",
    "    return {\n",
    "        \"tags\": tags,\n",
    "        \"vocabulary\": vocabulary,\n",
    "        \"log_transitions\": log_transitions,\n",
    "        \"log_emissions\": log_emissions,\n",
    "        \"log_unknown\": log_unknown,\n",
    "    }\n",
    "\n",
    "\n",
    "def viterbi_decode(words, params):\n",
    "    tags = params[\"tags\"]\n",
    "    log_trans = params[\"log_transitions\"]\n",
    "    log_emit = params[\"log_emissions\"]\n",
    "    log_unk = params[\"log_unknown\"]\n",
    "\n",
    "    dp = []\n",
    "    backpointer = []\n",
    "\n",
    "    first_dp = {}\n",
    "    first_bp = {}\n",
    "    for tag in tags:\n",
    "        trans_score = log_trans[START_TAG].get(tag, math.log(1e-12))\n",
    "        emit_score = log_emit[tag].get(words[0], log_unk[tag])\n",
    "        first_dp[tag] = trans_score + emit_score\n",
    "        first_bp[tag] = START_TAG\n",
    "    dp.append(first_dp)\n",
    "    backpointer.append(first_bp)\n",
    "\n",
    "    for t in range(1, len(words)):\n",
    "        curr_dp = {}\n",
    "        curr_bp = {}\n",
    "        word = words[t]\n",
    "        for tag in tags:\n",
    "            best_score = -math.inf\n",
    "            best_prev = None\n",
    "            emit_score = log_emit[tag].get(word, log_unk[tag])\n",
    "            for prev_tag in tags:\n",
    "                prev_score = dp[t - 1][prev_tag]\n",
    "                trans_score = log_trans[prev_tag].get(tag, math.log(1e-12))\n",
    "                score = prev_score + trans_score + emit_score\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_prev = prev_tag\n",
    "            curr_dp[tag] = best_score\n",
    "            curr_bp[tag] = best_prev\n",
    "        dp.append(curr_dp)\n",
    "        backpointer.append(curr_bp)\n",
    "\n",
    "    best_final_score = -math.inf\n",
    "    best_last_tag = None\n",
    "    for tag in tags:\n",
    "        score = dp[-1][tag] + log_trans[tag].get(END_TAG, math.log(1e-12))\n",
    "        if score > best_final_score:\n",
    "            best_final_score = score\n",
    "            best_last_tag = tag\n",
    "\n",
    "    sequence = [best_last_tag]\n",
    "    for t in range(len(words) - 1, 0, -1):\n",
    "        prev_tag = backpointer[t][sequence[-1]]\n",
    "        sequence.append(prev_tag)\n",
    "    sequence.reverse()\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def evaluate(predicted, gold):\n",
    "    correct = sum(p == g for p, g in zip(predicted, gold))\n",
    "    total = len(gold)\n",
    "    precision = correct / total if total else 0.0\n",
    "    recall = precision\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if precision else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "def cross_validate(sentences, k=5):\n",
    "    folds = make_folds(sentences, k=k)\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold_idx in range(k):\n",
    "        test_set = folds[fold_idx]\n",
    "        train_set = [s for i, fold in enumerate(folds) if i != fold_idx for s in fold]\n",
    "        params = train_hmm(train_set)\n",
    "\n",
    "        all_pred = []\n",
    "        all_gold = []\n",
    "        for words, tags in test_set:\n",
    "            if not words:\n",
    "                continue\n",
    "            pred_tags = viterbi_decode(words, params)\n",
    "            all_pred.extend(pred_tags)\n",
    "            all_gold.extend(tags)\n",
    "\n",
    "        precision, recall, f1 = evaluate(all_pred, all_gold)\n",
    "        fold_metrics.append((precision, recall, f1))\n",
    "        print(\n",
    "            f\"Fold {fold_idx + 1}: Precision={precision:.4f} \"\n",
    "            f\"Recall={recall:.4f} F1={f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    avg_precision = sum(p for p, _, _ in fold_metrics) / k\n",
    "    avg_recall = sum(r for _, r, _ in fold_metrics) / k\n",
    "    avg_f1 = sum(f for _, _, f in fold_metrics) / k\n",
    "    print(\n",
    "        f\"\\nAverage: Precision={avg_precision:.4f} \"\n",
    "        f\"Recall={avg_recall:.4f} F1={avg_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "data_path = Path(\"wsj_pos_tagged_en.txt\")\n",
    "sentences = read_tagged_corpus(data_path)\n",
    "cross_validate(sentences, k=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
