{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccb9ef6",
   "metadata": {},
   "source": [
    "Here we import:\n",
    "- `defaultdict` → helps us create nested dictionaries easily for trie nodes.\n",
    "- `Counter` → to count suffix occurrences.\n",
    "- `pprint` → pretty printing dictionaries (useful for debugging).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96818de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from collections import defaultdict, Counter\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f8362",
   "metadata": {},
   "source": [
    "We load all nouns from `brown_nouns.txt`.\n",
    "- Each line is stripped of whitespace and converted to lowercase.\n",
    "- We store all words in a list `words`.\n",
    "- We check the total number of words and print the first 20 for inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76900b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words loaded: 202793\n",
      "Sample words: ['investigation', 'primary', 'election', 'evidence', 'irregularities', 'place', 'jury', 'presentments', 'charge', 'election', 'praise', 'thanks', 'manner', 'election', 'term', 'jury', 'reports', 'irregularities', 'primary', 'handful']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset of nouns\n",
    "with open(\"brown_nouns.txt\", \"r\") as f:\n",
    "    words = [line.strip().lower() for line in f if line.strip()]\n",
    "\n",
    "print(\"Total words loaded:\", len(words))\n",
    "print(\"Sample words:\", words[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcd865",
   "metadata": {},
   "source": [
    "We define a **TrieNode** class:\n",
    "- `children`: dictionary mapping characters to next nodes.\n",
    "- `is_end`: marks if this node ends a word.\n",
    "- `count`: how many words pass through this node (used later for frequency).\n",
    "\n",
    "We define a **Trie** class with:\n",
    "- `insert(word)`: inserts a word character by character into the trie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bef357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)  # each node points to children\n",
    "        self.is_end = False                   # marks end of word\n",
    "        self.count = 0                        # frequency counter\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for ch in word:\n",
    "            node = node.children[ch]\n",
    "            node.count += 1\n",
    "        node.is_end = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb71ac0",
   "metadata": {},
   "source": [
    "We build two tries:\n",
    "1. **Prefix Trie** → words inserted left-to-right.\n",
    "2. **Suffix Trie** → words inserted right-to-left (so suffixes become prefixes).\n",
    "\n",
    "This allows us to analyze both perspectives when identifying stems/suffixes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7557055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tries built successfully!\n"
     ]
    }
   ],
   "source": [
    "# Build prefix trie (normal)\n",
    "prefix_trie = Trie()\n",
    "for word in words:\n",
    "    prefix_trie.insert(word)\n",
    "\n",
    "# Build suffix trie (reverse each word before inserting)\n",
    "suffix_trie = Trie()\n",
    "for word in words:\n",
    "    suffix_trie.insert(word[::-1])\n",
    "\n",
    "print(\"Tries built successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49d273",
   "metadata": {},
   "source": [
    "We define `find_split`:\n",
    "- Traverse the trie character by character.\n",
    "- Track where the **maximum branching** occurs (`max_branching`).\n",
    "- That index = point where stem ends and suffix begins.\n",
    "- If using suffix trie, we reverse the logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4be2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(word, trie, reverse=False):\n",
    "    \"\"\"\n",
    "    Traverse the trie for given word.\n",
    "    The node where maximum branching occurs = suffix boundary.\n",
    "    \"\"\"\n",
    "    node = trie.root\n",
    "    split_index = 0\n",
    "    max_branching = 0\n",
    "    \n",
    "    letters = word[::-1] if reverse else word\n",
    "    \n",
    "    for i, ch in enumerate(letters):\n",
    "        node = node.children.get(ch)\n",
    "        if not node:\n",
    "            break\n",
    "        branching = len(node.children)\n",
    "        if branching > max_branching:\n",
    "            max_branching = branching\n",
    "            split_index = i + 1\n",
    "    \n",
    "    if reverse:\n",
    "        stem = word[:-split_index] if split_index > 0 else word\n",
    "        suffix = word[-split_index:] if split_index > 0 else \"\"\n",
    "    else:\n",
    "        stem = word[:split_index] if split_index > 0 else word\n",
    "        suffix = word[split_index:] if split_index > 0 else \"\"\n",
    "    \n",
    "    return stem, suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce5663",
   "metadata": {},
   "source": [
    "We test our function on the first 50 words:\n",
    "- For each word, we compute stem+suffix using **Prefix Trie** and **Suffix Trie**.\n",
    "- We print results in the format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2012449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investigation | PrefixTrie: in+vestigation | SuffixTrie: investigati+on\n",
      "primary | PrefixTrie: p+rimary | SuffixTrie: primar+y\n",
      "election | PrefixTrie: e+lection | SuffixTrie: electi+on\n",
      "evidence | PrefixTrie: e+vidence | SuffixTrie: evidenc+e\n",
      "irregularities | PrefixTrie: i+rregularities | SuffixTrie: irregularitie+s\n",
      "place | PrefixTrie: p+lace | SuffixTrie: plac+e\n",
      "jury | PrefixTrie: ju+ry | SuffixTrie: jur+y\n",
      "presentments | PrefixTrie: p+resentments | SuffixTrie: presentment+s\n",
      "charge | PrefixTrie: c+harge | SuffixTrie: charg+e\n",
      "election | PrefixTrie: e+lection | SuffixTrie: electi+on\n",
      "praise | PrefixTrie: p+raise | SuffixTrie: prais+e\n",
      "thanks | PrefixTrie: t+hanks | SuffixTrie: thank+s\n",
      "manner | PrefixTrie: ma+nner | SuffixTrie: mann+er\n",
      "election | PrefixTrie: e+lection | SuffixTrie: electi+on\n",
      "term | PrefixTrie: t+erm | SuffixTrie: ter+m\n",
      "jury | PrefixTrie: ju+ry | SuffixTrie: jur+y\n",
      "reports | PrefixTrie: re+ports | SuffixTrie: report+s\n",
      "irregularities | PrefixTrie: i+rregularities | SuffixTrie: irregularitie+s\n",
      "primary | PrefixTrie: p+rimary | SuffixTrie: primar+y\n",
      "handful | PrefixTrie: ha+ndful | SuffixTrie: handfu+l\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for word in words[:50]:  # testing first 50 words\n",
    "    stem_p, suf_p = find_split(word, prefix_trie, reverse=False)\n",
    "    stem_s, suf_s = find_split(word, suffix_trie, reverse=True)\n",
    "    results.append((word, stem_p, suf_p, stem_s, suf_s))\n",
    "\n",
    "# Display few results\n",
    "for r in results[:20]:\n",
    "    print(f\"{r[0]} | PrefixTrie: {r[1]}+{r[2]} | SuffixTrie: {r[3]}+{r[4]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6338a",
   "metadata": {},
   "source": [
    "We compute **frequency of suffixes**:\n",
    "- Use suffix trie splits.\n",
    "- Count how many times each suffix occurs.\n",
    "- Convert frequencies into probabilities = `freq / total_words`.\n",
    "- Print top 10 suffixes with their probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870d24f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common suffixes:\n",
      "s -> freq=55539, prob=0.2739\n",
      "e -> freq=35090, prob=0.1730\n",
      "t -> freq=19226, prob=0.0948\n",
      "on -> freq=14811, prob=0.0730\n",
      "y -> freq=14792, prob=0.0729\n",
      "er -> freq=8663, prob=0.0427\n",
      "d -> freq=7965, prob=0.0393\n",
      "m -> freq=4355, prob=0.0215\n",
      "ing -> freq=3869, prob=0.0191\n",
      "k -> freq=3658, prob=0.0180\n"
     ]
    }
   ],
   "source": [
    "suffix_counter = Counter()\n",
    "\n",
    "for word in words:\n",
    "    _, suffix = find_split(word, suffix_trie, reverse=True)\n",
    "    if suffix:\n",
    "        suffix_counter[suffix] += 1\n",
    "\n",
    "print(\"Most common suffixes:\")\n",
    "for suf, freq in suffix_counter.most_common(10):\n",
    "    prob = freq / len(words)\n",
    "    print(f\"{suf} -> freq={freq}, prob={prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc2d9c",
   "metadata": {},
   "source": [
    "Compare Prefix vs. Suffix Trie Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eccd8f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word | PrefixTrie (Stem+Suffix) | SuffixTrie (Stem+Suffix)\n",
      "------------------------------------------------------------\n",
      "investigation | in+vestigation | investigati+on\n",
      "primary | p+rimary | primar+y\n",
      "election | e+lection | electi+on\n",
      "evidence | e+vidence | evidenc+e\n",
      "irregularities | i+rregularities | irregularitie+s\n",
      "place | p+lace | plac+e\n",
      "jury | ju+ry | jur+y\n",
      "presentments | p+resentments | presentment+s\n",
      "charge | c+harge | charg+e\n",
      "election | e+lection | electi+on\n",
      "praise | p+raise | prais+e\n",
      "thanks | t+hanks | thank+s\n",
      "manner | ma+nner | mann+er\n",
      "election | e+lection | electi+on\n",
      "term | t+erm | ter+m\n",
      "jury | ju+ry | jur+y\n",
      "reports | re+ports | report+s\n",
      "irregularities | i+rregularities | irregularitie+s\n",
      "primary | p+rimary | primar+y\n",
      "handful | ha+ndful | handfu+l\n",
      "reports | re+ports | report+s\n",
      "jury | ju+ry | jur+y\n",
      "interest | in+terest | interes+t\n",
      "election | e+lection | electi+on\n",
      "number | nu+mber | numb+er\n",
      "voters | vo+ters | voter+s\n",
      "size | s+ize | siz+e\n",
      "city | c+ity | cit+y\n",
      "jury | ju+ry | jur+y\n",
      "registration | re+gistration | registrati+on\n"
     ]
    }
   ],
   "source": [
    "# Compare prefix vs. suffix results for all words\n",
    "comparison_results = []\n",
    "\n",
    "for word in words:\n",
    "    stem_p, suf_p = find_split(word, prefix_trie, reverse=False)\n",
    "    stem_s, suf_s = find_split(word, suffix_trie, reverse=True)\n",
    "    comparison_results.append((word, stem_p, suf_p, stem_s, suf_s))\n",
    "\n",
    "# Display a sample of comparisons\n",
    "print(\"Word | PrefixTrie (Stem+Suffix) | SuffixTrie (Stem+Suffix)\")\n",
    "print(\"-\"*60)\n",
    "for r in comparison_results[:30]:\n",
    "    print(f\"{r[0]} | {r[1]}+{r[2]} | {r[3]}+{r[4]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa45f4e",
   "metadata": {},
   "source": [
    "**Quantitative Analysis**\n",
    "\n",
    "To measure which trie performs better for stemming:\n",
    "- We check **suffix frequencies** (already computed).\n",
    "- We measure **average suffix length** and **diversity**.\n",
    "- Higher frequency & shorter suffixes indicate better morphological segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8773365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix Trie Analysis:\n",
      "Average Prefix Length: 5.153718323610775\n",
      "Top 10 prefixes: [('y', 1641), ('ime', 1569), ('n', 1298), ('nd', 1071), ('ears', 1027), ('fe', 927), ('eople', 828), ('se', 826), ('en', 792), ('ear', 784)]\n",
      "\n",
      "Suffix Trie Analysis:\n",
      "Average Suffix Length: 1.250768024537336\n",
      "Top 10 suffixes: [('s', 55539), ('e', 35090), ('t', 19226), ('on', 14811), ('y', 14792), ('er', 8663), ('d', 7965), ('m', 4355), ('ing', 3869), ('k', 3658)]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_trie(trie, reverse=False):\n",
    "    suffix_counter = Counter()\n",
    "    suffix_lengths = []\n",
    "    \n",
    "    for word in words:\n",
    "        _, suffix = find_split(word, trie, reverse=reverse)\n",
    "        if suffix:\n",
    "            suffix_counter[suffix] += 1\n",
    "            suffix_lengths.append(len(suffix))\n",
    "    \n",
    "    avg_suffix_len = sum(suffix_lengths)/len(suffix_lengths) if suffix_lengths else 0\n",
    "    return suffix_counter, avg_suffix_len\n",
    "\n",
    "# Evaluate prefix trie\n",
    "prefix_suffix_counter, prefix_avg_len = evaluate_trie(prefix_trie, reverse=False)\n",
    "\n",
    "# Evaluate suffix trie\n",
    "suffix_suffix_counter, suffix_avg_len = evaluate_trie(suffix_trie, reverse=True)\n",
    "\n",
    "print(\"Prefix Trie Analysis:\")\n",
    "print(\"Average Prefix Length:\", prefix_avg_len)\n",
    "print(\"Top 10 prefixes:\", prefix_suffix_counter.most_common(10))\n",
    "\n",
    "print(\"\\nSuffix Trie Analysis:\")\n",
    "print(\"Average Suffix Length:\", suffix_avg_len)\n",
    "print(\"Top 10 suffixes:\", suffix_suffix_counter.most_common(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa63d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
