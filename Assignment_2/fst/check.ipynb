{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9a30b4",
   "metadata": {},
   "source": [
    "#### Defined input/output alphabets for sigma & gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b84903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Alphabet Σ: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<SUF_S>', '<SUF_ES>', '<SUF_IES>', '#']\n",
      "Output Alphabet Γ: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '+N+SG', '+N+PL']\n"
     ]
    }
   ],
   "source": [
    "# Input alphabet Σ = {a…z, s, es, ies, #}\n",
    "# (letters + suffix markers + end-of-word)\n",
    "Sigma = list(\"abcdefghijklmnopqrstuvwxyz\") + [\"<SUF_S>\", \"<SUF_ES>\", \"<SUF_IES>\", \"#\"]\n",
    "\n",
    "# Output alphabet Γ = {a…z, +, N, SG, PL}\n",
    "Gamma = list(\"abcdefghijklmnopqrstuvwxyz\") + [\"+N+SG\", \"+N+PL\"]\n",
    "\n",
    "print(\"Input Alphabet Σ:\", Sigma)\n",
    "print(\"Output Alphabet Γ:\", Gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d089c",
   "metadata": {},
   "source": [
    "#### Defined states Q, start state q0, final states F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9f5a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States Q: {'q0', 'qACCEPT', 'qPL', 'qSG'}\n",
      "Start State: q0\n",
      "Final States F: {'qACCEPT', 'qSG'}\n"
     ]
    }
   ],
   "source": [
    "# States Q\n",
    "Q = {\n",
    "    \"q0\",       # initial state (reading root letters)\n",
    "    \"qPL\",      # plural branch after consuming suffix\n",
    "    \"qSG\",      # singular branch at end-of-word\n",
    "    \"qACCEPT\"   # final accepting state\n",
    "}\n",
    "\n",
    "q0 = \"q0\"          # start state\n",
    "F  = {\"qSG\", \"qACCEPT\"}   # set of final states\n",
    "\n",
    "print(\"States Q:\", Q)\n",
    "print(\"Start State:\", q0)\n",
    "print(\"Final States F:\", F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a2987",
   "metadata": {},
   "source": [
    "#### Defined delta the transition function as dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48fbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# δ: (state, input_symbol) -> (next_state, output)\n",
    "\n",
    "delta = {}\n",
    "\n",
    "# 1) Copy root letters in q0\n",
    "for ch in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "    delta[(q0, ch)] = (q0, ch)\n",
    "\n",
    "# 2) Singular branch: if we reach end-of-word from q0\n",
    "delta[(q0, \"#\")] = (\"qSG\", \"+N+SG\")\n",
    "\n",
    "# 3) Plural suffix branches from q0\n",
    "delta[(q0, \"<SUF_S>\")]   = (\"qPL\", \"+N+PL\")\n",
    "delta[(q0, \"<SUF_ES>\")]  = (\"qPL\", \"+N+PL\")\n",
    "delta[(q0, \"<SUF_IES>\")] = (\"qPL\", \"y+N+PL\")  # we output 'y' as root + plural tag\n",
    "\n",
    "# 4) End-of-word after plural → accept\n",
    "delta[(\"qPL\", \"#\")] = (\"qACCEPT\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b879fc8",
   "metadata": {},
   "source": [
    "#### Writing the analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b10f0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fst(word_tokens):\n",
    "    state = q0\n",
    "    output = []\n",
    "    for sym in word_tokens:\n",
    "        if (state, sym) not in delta:\n",
    "            return \"Invalid Word\"\n",
    "        state, out = delta[(state, sym)]\n",
    "        if out:\n",
    "            output.append(out)\n",
    "    if state in F:\n",
    "        return \"\".join(output)\n",
    "    return \"Invalid Word\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af78e10",
   "metadata": {},
   "source": [
    "#### Another transition table tok_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81c533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input alphabet\n",
    "letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "tok_delta = {}\n",
    "\n",
    "# --- 1) Default: copy letters\n",
    "for ch in letters:\n",
    "    tok_delta[(\"q0\", ch)] = (\"q0\", [ch])\n",
    "\n",
    "# --- 2) End marker\n",
    "tok_delta[(\"q0\", \"#\")] = (\"qACCEPT\", [\"#\"])\n",
    "\n",
    "# --- 3) Suffix rules\n",
    "\n",
    "# (a) plain \"s\"\n",
    "tok_delta[(\"q0\", \"s\")] = (\"qS\", [])                  # buffer 's'\n",
    "tok_delta[(\"qS\", \"#\")] = (\"qACCEPT\", [\"<SUF_S>\", \"#\"])   # s at end → <SUF_S>\n",
    "tok_delta[(\"qS\", \"s\")] = (\"q0\", [\"s\", \"s\"])        # double s stays stem\n",
    "for ch in letters:\n",
    "    if ch != \"s\":\n",
    "        tok_delta[(\"qS\", ch)] = (\"q0\", [\"<SUF_S>\", ch])   # release 's' if not suffix\n",
    "\n",
    "# (b) \"es\"\n",
    "tok_delta[(\"q0\", \"e\")] = (\"qE\", [])                 # buffer 'e'\n",
    "tok_delta[(\"qE\", \"s\")] = (\"qACCEPT\", [\"<SUF_ES>\", \"#\"])  # es at end\n",
    "tok_delta[(\"qE\", \"#\")] = (\"qACCEPT\", [\"e\", \"#\"])         # lone 'e' at end\n",
    "for ch in letters:\n",
    "    if ch != \"s\":\n",
    "        tok_delta[(\"qE\", ch)] = (\"q0\", [\"e\", ch])         # release 'e' if not suffix\n",
    "\n",
    "# (c) \"ies\"\n",
    "tok_delta[(\"q0\", \"i\")] = (\"qI\", [])                 # buffer 'i'\n",
    "tok_delta[(\"qI\", \"e\")] = (\"qIE\", [])               # buffer 'ie'\n",
    "tok_delta[(\"qIE\", \"s\")] = (\"qACCEPT\", [\"<SUF_IES>\", \"#\"]) # ies at end\n",
    "tok_delta[(\"qI\", \"#\")] = (\"qACCEPT\", [\"i\", \"#\"])          # lone 'i'\n",
    "tok_delta[(\"qIE\", \"#\")] = (\"qACCEPT\", [\"i\", \"e\", \"#\"])    # lone 'ie'\n",
    "for ch in letters:\n",
    "    if ch != \"e\":\n",
    "        tok_delta[(\"qI\", ch)] = (\"q0\", [\"i\", ch])          # release 'i' if not suffix\n",
    "for ch in letters:\n",
    "    if ch != \"s\":\n",
    "        tok_delta[(\"qIE\", ch)] = (\"q0\", [\"i\", \"e\", ch])    # release 'ie' if not suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f19aa",
   "metadata": {},
   "source": [
    "#### Adding a tokenizer runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0b2fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tokenizer(word):\n",
    "    state = \"q0\"\n",
    "    output = []\n",
    "    for ch in list(word) + [\"#\"]:\n",
    "        if (state, ch) not in tok_delta:\n",
    "            return [\"Invalid\"]\n",
    "        state, out = tok_delta[(state, ch)]\n",
    "        if out:\n",
    "            # out is a list of strings → extend, not append\n",
    "            output.extend(out)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0527ca",
   "metadata": {},
   "source": [
    "#### Pipeline from tokenizer to analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d4e5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_word(word):\n",
    "    toks = run_tokenizer(word.lower())\n",
    "    return word, toks, run_fst(toks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98028cb8",
   "metadata": {},
   "source": [
    "#### Testing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b037304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fox', ['f', 'o', 'x', '#'], 'fox+N+SG')\n",
      "('foxes', ['Invalid'], 'Invalid Word')\n",
      "('bags', ['b', 'a', 'g', '<SUF_S>', '#'], 'bag+N+PL')\n",
      "('tries', ['Invalid'], 'Invalid Word')\n",
      "('class', ['c', 'l', 'a', 's', 's', '#'], 'class+N+SG')\n",
      "('classes', ['Invalid'], 'Invalid Word')\n",
      "('bus', ['b', 'u', '<SUF_S>', '#'], 'bu+N+PL')\n",
      "('buses', ['b', 'u', '<SUF_S>', 'e', '<SUF_S>', '#'], 'Invalid Word')\n",
      "('cactus', ['c', 'a', 'c', 't', 'u', '<SUF_S>', '#'], 'cactu+N+PL')\n",
      "('cacti', ['c', 'a', 'c', 't', 'i', '#'], 'cacti+N+SG')\n"
     ]
    }
   ],
   "source": [
    "for w in [\"fox\", \"foxes\", \"bags\", \"tries\",\"class\",\"classes\", \"bus\", \"buses\", \"cactus\", \"cacti\"]:\n",
    "    print(analyze_word(w))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
